{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO5D7cmWr/w/WQNlI9W59hQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kabilan942/TensorFlow/blob/main/01_TF_Neural_Network_Regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ldKPd2lx24XH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "49b07151-6293-4a74-cad6-c3b178dcacc9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.8.2'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "tf.__version__"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating Data to View and Fit"
      ],
      "metadata": {
        "id": "Fe3fsh-8u4oF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt "
      ],
      "metadata": {
        "id": "5VdROcAPu31G"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# creating features\n",
        "X = np.array([-7., -4., -1., 2., 5., 8., 11., 14.])\n",
        "\n",
        "# creating labels\n",
        "y = np.array([3., 6., 9., 12., 15., 18., 21., 24.])\n",
        "\n",
        "# visualizing it\n",
        "plt.scatter(X, y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "id": "sbj-PDXX5RGK",
        "outputId": "a209fdf1-8a85-486b-8dd1-9b644b23a013"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7f0ed1632bd0>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y == X + 10"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hM3M431W5mMG",
        "outputId": "bb6a5205-2912-4b7c-fb09-eb597ccdee38"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ True,  True,  True,  True,  True,  True,  True,  True])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Input and Output shapes"
      ],
      "metadata": {
        "id": "CIKozkH85r4u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Demo tensor for house price prediction problem\n",
        "\n",
        "house_info = tf.constant(['Bedroom', 'Bathroom', 'Garage'])\n",
        "price_info = tf.constant([939700])\n",
        "house_info, price_info"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xtNKYTSw5-rY",
        "outputId": "96ccc957-9a2c-40b0-ecd4-c6544f5264da"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(3,), dtype=string, numpy=array([b'Bedroom', b'Bathroom', b'Garage'], dtype=object)>,\n",
              " <tf.Tensor: shape=(1,), dtype=int32, numpy=array([939700], dtype=int32)>)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X[0], y[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vwbn42CG6TyX",
        "outputId": "4f073543-f058-4c76-89d6-e787475973ac"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(-7.0, 3.0)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X[1], y[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RLYmuGTx6ZrH",
        "outputId": "68af2456-9339-4724-9fd5-312255f15b15"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(-4.0, 6.0)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X[0], X[0].shape, X[0].ndim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EUF1NeW06bZY",
        "outputId": "0bd61309-d50c-410e-d32a-cbf0989bc726"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(-7.0, (), 0)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = X[0].shape\n",
        "output_shape = y[0].shape\n",
        "input_shape, output_shape "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A_4MkZrr6ee7",
        "outputId": "fcfe3aba-2255-4838-dfd2-0af2763e95b1"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((), ())"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Turning the Numpy arrays into tensors\n",
        "X = tf.cast(tf.constant(X), dtype=tf.float32)\n",
        "y = tf.cast(tf.constant(y), dtype=tf.float32)\n",
        "X, y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jFxy9pB866YI",
        "outputId": "db843e32-4a62-410f-a066-fedd0e93f404"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(8,), dtype=float32, numpy=array([-7., -4., -1.,  2.,  5.,  8., 11., 14.], dtype=float32)>,\n",
              " <tf.Tensor: shape=(8,), dtype=float32, numpy=array([ 3.,  6.,  9., 12., 15., 18., 21., 24.], dtype=float32)>)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = X[0].shape\n",
        "output_shape = y[0].shape\n",
        "input_shape, output_shape "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EIGHWYJ67IX6",
        "outputId": "93e1e243-6a50-44f4-f2db-24d42d695eb4"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([]), TensorShape([]))"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Steps in Modelling with TensorFlow\n",
        "\n",
        "1. **Creating a model** - define the input and output layers, as well as the hidden layers of a deep learning model.\n",
        "2. **Compiling a model** - define the loss function and the optimizer (SGD, Adam - tells model how to improve loss function) and evaluation metrics.\n",
        "3. **Fitting a model** - letting the model try the patterns between X & y (features & labels)."
      ],
      "metadata": {
        "id": "PSr5O2827Tjd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you're using TensorFlow 2.7.0+, the `fit()` function no longer upscales input data to go from (batch_size, ) to (batch_size, 1). To fix this, you'll need to expand the dimension of input data using `tf.expand_dims(input_data, axis=-1)`"
      ],
      "metadata": {
        "id": "t0Fnw7FqBJPz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# 1. Create a model using the Sequential API  (sequentially go through the following)\n",
        "# It groups a linear stack of layers into a tf.keras.Model\n",
        "model = tf.keras.Sequential([tf.keras.layers.Dense(1)])  # 1 because X has only 1 feature and it is mapped to one label\n",
        "\n",
        "# 2. Comile the model\n",
        "model.compile(loss = tf.keras.losses.mae, \n",
        "              optimizer = tf.keras.optimizers.SGD(),\n",
        "              metrics = ['mae'])\n",
        "\n",
        "# 3. Fit the model\n",
        "model.fit(tf.expand_dims(X, axis=-1), y, epochs=5)  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QyQwEisE7LdE",
        "outputId": "6d2636e7-9f27-4249-82ac-a3bcdf0907af"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1/1 [==============================] - 0s 278ms/step - loss: 11.5048 - mae: 11.5048\n",
            "Epoch 2/5\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 11.3723 - mae: 11.3723\n",
            "Epoch 3/5\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 11.2398 - mae: 11.2398\n",
            "Epoch 4/5\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 11.1073 - mae: 11.1073\n",
            "Epoch 5/5\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 10.9748 - mae: 10.9748\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f0ecb356610>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model = tf.keras.Sequential()\n",
        "# model.add(tf.keras.layers.Dense(1))\n",
        "# model.add(tf.keras.layers.Dense(1))\n",
        "\n",
        "# equivalent\n",
        "\n",
        "# model = tf.keras.Sequential(tf.keras.layers.Dense(1), tf.keras.layers.Dense)"
      ],
      "metadata": {
        "id": "RSMunibHcU82"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X, y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FYj0-3u1B1Ax",
        "outputId": "f15ea810-80a7-458d-c723-59ea9c3950aa"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(8,), dtype=float32, numpy=array([-7., -4., -1.,  2.,  5.,  8., 11., 14.], dtype=float32)>,\n",
              " <tf.Tensor: shape=(8,), dtype=float32, numpy=array([ 3.,  6.,  9., 12., 15., 18., 21., 24.], dtype=float32)>)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Making a prediction with our model\n",
        "# Since there's no test data, we'll pass a random value of X\n",
        "model.predict([17])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AUN0O3NEB25N",
        "outputId": "644f6803-9c79-444f-8e26-a204551c7114"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[12.716021]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "There's a lot of error in this model"
      ],
      "metadata": {
        "id": "vB0f42zqDtmz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Improving our Model\n",
        "\n",
        "We can improve our model, by altering the steps we took to create a model.\n",
        "\n",
        "1. **Creating a model** - here you might want to add more layers, increase the number of hidden units (also called neurons) within each layer, change the activation functions of each layer.\n",
        "2. **Compiling a model** - you might want to choose optimization function or perhaps change the learning rate of the optimization function.\n",
        "3. **Fitting a model** - perhaps you could fit a model for more epochs (leave it training for longer) or on more data (give the model more examples to learn from- instead of subset of training data, fit the model with the whole training dataset).\n"
      ],
      "metadata": {
        "id": "EfAVfqx0DyzL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Common ways to improve a Deep model:**\n",
        "* Fitting for longer - increasing number of epochs\n",
        "* Adding layers\n",
        "* Increase number of hidden units\n",
        "* Change the activation functions\n",
        "* Change the optimization functions\n",
        "* Change the learning rate - most important HPT in most neural networks\n",
        "* Fitting on more data"
      ],
      "metadata": {
        "id": "YVs72L3DkG75"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fitting on more data"
      ],
      "metadata": {
        "id": "0fikYDwLkByA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's rebuild our model\n",
        "\n",
        "# 1.Create the model\n",
        "model = tf.keras.Sequential([tf.keras.layers.Dense(1)])\n",
        "\n",
        "# 2. Compile the model\n",
        "model.compile(loss=tf.keras.losses.mae, \n",
        "              optimizer=tf.keras.optimizers.SGD(),\n",
        "              metrics=['mae'])\n",
        "\n",
        "# 3. Fit the model (this time we'll train the model for longer - 100 epochs instead of 5)\n",
        "model.fit(tf.expand_dims(X, axis=-1), y, epochs=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6z2RG3wSD8Qt",
        "outputId": "9412ecb2-a5f3-4051-9826-c40e54ff920f"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1/1 [==============================] - 0s 271ms/step - loss: 11.2219 - mae: 11.2219\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 11.0894 - mae: 11.0894\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 10.9569 - mae: 10.9569\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 10.8244 - mae: 10.8244\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 10.6919 - mae: 10.6919\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 10.5594 - mae: 10.5594\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 10.4269 - mae: 10.4269\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 10.2944 - mae: 10.2944\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 10.1619 - mae: 10.1619\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 10.0294 - mae: 10.0294\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 9.8969 - mae: 9.8969\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 9.7644 - mae: 9.7644\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 9.6319 - mae: 9.6319\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 9.4994 - mae: 9.4994\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 9.3669 - mae: 9.3669\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 9.2344 - mae: 9.2344\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 9.1019 - mae: 9.1019\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 8.9694 - mae: 8.9694\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.8369 - mae: 8.8369\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 8.7044 - mae: 8.7044\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 8.5719 - mae: 8.5719\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 8.4394 - mae: 8.4394\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 8.3069 - mae: 8.3069\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 8.1744 - mae: 8.1744\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.0419 - mae: 8.0419\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.9094 - mae: 7.9094\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.7769 - mae: 7.7769\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.6444 - mae: 7.6444\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.5119 - mae: 7.5119\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.3794 - mae: 7.3794\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.2750 - mae: 7.2750\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.2694 - mae: 7.2694\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.2638 - mae: 7.2638\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.2581 - mae: 7.2581\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.2525 - mae: 7.2525\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.2469 - mae: 7.2469\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.2412 - mae: 7.2412\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.2356 - mae: 7.2356\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.2300 - mae: 7.2300\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.2244 - mae: 7.2244\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.2188 - mae: 7.2188\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.2131 - mae: 7.2131\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.2075 - mae: 7.2075\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.2019 - mae: 7.2019\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.1962 - mae: 7.1962\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.1906 - mae: 7.1906\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.1850 - mae: 7.1850\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.1794 - mae: 7.1794\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 7.1737 - mae: 7.1737\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.1681 - mae: 7.1681\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.1625 - mae: 7.1625\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.1569 - mae: 7.1569\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.1512 - mae: 7.1512\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.1456 - mae: 7.1456\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.1400 - mae: 7.1400\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.1344 - mae: 7.1344\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.1287 - mae: 7.1287\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.1231 - mae: 7.1231\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.1175 - mae: 7.1175\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.1119 - mae: 7.1119\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.1062 - mae: 7.1062\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.1006 - mae: 7.1006\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.0950 - mae: 7.0950\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.0894 - mae: 7.0894\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.0838 - mae: 7.0838\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.0781 - mae: 7.0781\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.0725 - mae: 7.0725\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.0669 - mae: 7.0669\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.0613 - mae: 7.0613\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.0556 - mae: 7.0556\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.0500 - mae: 7.0500\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.0444 - mae: 7.0444\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.0388 - mae: 7.0388\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.0331 - mae: 7.0331\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.0275 - mae: 7.0275\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.0219 - mae: 7.0219\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.0163 - mae: 7.0163\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.0106 - mae: 7.0106\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.0050 - mae: 7.0050\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 6.9994 - mae: 6.9994\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 6.9938 - mae: 6.9938\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.9881 - mae: 6.9881\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.9825 - mae: 6.9825\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.9769 - mae: 6.9769\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.9713 - mae: 6.9713\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 6.9656 - mae: 6.9656\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.9600 - mae: 6.9600\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.9544 - mae: 6.9544\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.9488 - mae: 6.9488\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.9431 - mae: 6.9431\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 6.9375 - mae: 6.9375\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.9319 - mae: 6.9319\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.9263 - mae: 6.9263\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.9206 - mae: 6.9206\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.9150 - mae: 6.9150\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.9094 - mae: 6.9094\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.9038 - mae: 6.9038\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 6.8981 - mae: 6.8981\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 6.8925 - mae: 6.8925\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 6.8869 - mae: 6.8869\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f0ecb24a1d0>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Just by altering one hyperparameter (number of epochs), the loss and mae has reduced from close to 11 to 7"
      ],
      "metadata": {
        "id": "JZ04hCAnaqnL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " X, y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KIZOOFt-KUaf",
        "outputId": "00b54663-47a5-4f74-c7d9-3c46b66da29a"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(8,), dtype=float32, numpy=array([-7., -4., -1.,  2.,  5.,  8., 11., 14.], dtype=float32)>,\n",
              " <tf.Tensor: shape=(8,), dtype=float32, numpy=array([ 3.,  6.,  9., 12., 15., 18., 21., 24.], dtype=float32)>)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prediction of updated model\n",
        "model.predict([17])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f6vDlkO-c6jB",
        "outputId": "eb709b71-5327-421c-d41a-79984869fdb8"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[29.739855]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model has given a label of 29.739 from close to 12 (previously) for the input which is close to the actual output - 27"
      ],
      "metadata": {
        "id": "R9a3vdxBdBbQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Adding layers with hidden units"
      ],
      "metadata": {
        "id": "3wy2Sc89k080"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's rebuild our model by changing another HPT - \n",
        "\n",
        "# 1. Create a model (with an extra hidden layer with 100 hidden units)\n",
        "model = tf.keras.Sequential([tf.keras.layers.Dense(100, activation='relu'),\n",
        "                             tf.keras.layers.Dense(1)])\n",
        "\n",
        "# 2. Compile the model\n",
        "model.compile(loss='mae', \n",
        "              optimizer=tf.keras.optimizers.SGD(),\n",
        "              metrics = ['mae'])\n",
        "\n",
        "# 3. Fit the model\n",
        "model.fit(tf.expand_dims(X, axis=-1), y, epochs=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3mHitjgmdsMF",
        "outputId": "f792a236-7fbd-42aa-d28e-63a308873c03"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1/1 [==============================] - 0s 305ms/step - loss: 12.7339 - mae: 12.7339\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 12.2088 - mae: 12.2088\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 11.6861 - mae: 11.6861\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 11.1615 - mae: 11.1615\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 10.6118 - mae: 10.6118\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 10.0388 - mae: 10.0388\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 9.4399 - mae: 9.4399\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 8.8100 - mae: 8.8100\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 8.1464 - mae: 8.1464\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.4413 - mae: 7.4413\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.6796 - mae: 6.6796\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 5.8587 - mae: 5.8587\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 4.9722 - mae: 4.9722\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 4.1661 - mae: 4.1661\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 4.0374 - mae: 4.0374\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.9411 - mae: 3.9411\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.9415 - mae: 3.9415\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.9232 - mae: 3.9232\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.9527 - mae: 3.9527\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.8979 - mae: 3.8979\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.9597 - mae: 3.9597\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.8929 - mae: 3.8929\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.9454 - mae: 3.9454\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.8998 - mae: 3.8998\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.9221 - mae: 3.9221\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.9144 - mae: 3.9144\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.9019 - mae: 3.9019\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.9215 - mae: 3.9215\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.8765 - mae: 3.8765\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.9287 - mae: 3.9287\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.8624 - mae: 3.8624\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.9235 - mae: 3.9235\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.8695 - mae: 3.8695\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.9051 - mae: 3.9051\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.8843 - mae: 3.8843\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.8795 - mae: 3.8795\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.8916 - mae: 3.8916\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.8538 - mae: 3.8538\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.8990 - mae: 3.8990\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.8331 - mae: 3.8331\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.9004 - mae: 3.9004\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.8448 - mae: 3.8448\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.8816 - mae: 3.8816\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.8554 - mae: 3.8554\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.8558 - mae: 3.8558\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.8628 - mae: 3.8628\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.8298 - mae: 3.8298\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.8705 - mae: 3.8705\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.8049 - mae: 3.8049\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.8783 - mae: 3.8783\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.8200 - mae: 3.8200\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.8569 - mae: 3.8569\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.8275 - mae: 3.8275\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.8308 - mae: 3.8308\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.8353 - mae: 3.8353\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.8046 - mae: 3.8046\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.8431 - mae: 3.8431\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.7782 - mae: 3.7782\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.8572 - mae: 3.8572\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.7930 - mae: 3.7930\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.8310 - mae: 3.8310\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.8008 - mae: 3.8008\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.8045 - mae: 3.8045\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.8087 - mae: 3.8087\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.7780 - mae: 3.7780\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.8168 - mae: 3.8168\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.7558 - mae: 3.7558\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.8302 - mae: 3.8302\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.7672 - mae: 3.7672\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.8036 - mae: 3.8036\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.7752 - mae: 3.7752\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.7769 - mae: 3.7769\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.7833 - mae: 3.7833\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.7501 - mae: 3.7501\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.7925 - mae: 3.7925\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.7343 - mae: 3.7343\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.8019 - mae: 3.8019\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.7424 - mae: 3.7424\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.7750 - mae: 3.7750\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.7506 - mae: 3.7506\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.7480 - mae: 3.7480\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.7589 - mae: 3.7589\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.7209 - mae: 3.7209\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.7726 - mae: 3.7726\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.7103 - mae: 3.7103\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.7723 - mae: 3.7723\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.7186 - mae: 3.7186\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.7450 - mae: 3.7450\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.7270 - mae: 3.7270\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.7178 - mae: 3.7178\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.7355 - mae: 3.7355\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.6929 - mae: 3.6929\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.7515 - mae: 3.7515\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.6873 - mae: 3.6873\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.7413 - mae: 3.7413\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.6958 - mae: 3.6958\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.7138 - mae: 3.7138\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.7044 - mae: 3.7044\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.6862 - mae: 3.6862\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.7131 - mae: 3.7131\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f0ecb0aefd0>"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The loss has come down to 3.7131 from the previous loss of 6.889"
      ],
      "metadata": {
        "id": "QhTapE9ddPz-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X, y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZH6u_Np3fKtr",
        "outputId": "8f4bfb32-0baf-4062-ece1-f2b7f307ab22"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(8,), dtype=float32, numpy=array([-7., -4., -1.,  2.,  5.,  8., 11., 14.], dtype=float32)>,\n",
              " <tf.Tensor: shape=(8,), dtype=float32, numpy=array([ 3.,  6.,  9., 12., 15., 18., 21., 24.], dtype=float32)>)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.predict([17.0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cs_QlvmsfNwa",
        "outputId": "2f4469fe-2023-4eff-bf61-4c495854cf78"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[31.856882]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The prediction must be 27 and this predicts 31.856; This model predicted worser than the previous model even though the loss is lesser. Thus, the model is **overfitting**."
      ],
      "metadata": {
        "id": "Nk4JajB4fPLN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Changing the Activation function"
      ],
      "metadata": {
        "id": "RihydsdRk7o3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# using activation = None instead of 'relu'\n",
        "\n",
        "model = tf.keras.Sequential([tf.keras.layers.Dense(100, activation=None),\n",
        "                             tf.keras.layers.Dense(1)])\n",
        "\n",
        "model.compile(loss='mae',\n",
        "              optimizer=tf.keras.optimizers.SGD(),\n",
        "              metrics='mae')\n",
        "\n",
        "model.fit(tf.expand_dims(X, axis=-1), y, epochs=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Glror90lfmG9",
        "outputId": "07a91ed5-8c3f-45ed-c8a5-eee277365c5d"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1/1 [==============================] - 1s 632ms/step - loss: 13.4562 - mae: 13.4562\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 12.9006 - mae: 12.9006\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 12.3433 - mae: 12.3433\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 11.7814 - mae: 11.7814\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 11.2120 - mae: 11.2120\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 10.6322 - mae: 10.6322\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 10.0390 - mae: 10.0390\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 9.4293 - mae: 9.4293\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.8000 - mae: 8.8000\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.1478 - mae: 8.1478\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.4695 - mae: 7.4695\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 7.2162 - mae: 7.2162\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.1950 - mae: 7.1950\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.1737 - mae: 7.1737\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.1523 - mae: 7.1523\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 7.1309 - mae: 7.1309\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.1094 - mae: 7.1094\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 7.0879 - mae: 7.0879\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.0663 - mae: 7.0663\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 7.0446 - mae: 7.0446\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.0229 - mae: 7.0229\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 7.0011 - mae: 7.0011\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 6.9792 - mae: 6.9792\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 6.9573 - mae: 6.9573\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 6.9352 - mae: 6.9352\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 6.9217 - mae: 6.9217\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 6.9052 - mae: 6.9052\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 6.8835 - mae: 6.8835\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 6.8617 - mae: 6.8617\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.8397 - mae: 6.8397\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.8177 - mae: 6.8177\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.7955 - mae: 6.7955\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.7732 - mae: 6.7732\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.7508 - mae: 6.7508\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.7283 - mae: 6.7283\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.7057 - mae: 6.7057\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.6829 - mae: 6.6829\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.6600 - mae: 6.6600\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.6370 - mae: 6.6370\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.6138 - mae: 6.6138\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.5905 - mae: 6.5905\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 6.5670 - mae: 6.5670\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 6.5434 - mae: 6.5434\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.5196 - mae: 6.5196\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.4957 - mae: 6.4957\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.4716 - mae: 6.4716\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.4473 - mae: 6.4473\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 6.4229 - mae: 6.4229\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.3983 - mae: 6.3983\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 6.3735 - mae: 6.3735\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.3575 - mae: 6.3575\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.3450 - mae: 6.3450\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.3203 - mae: 6.3203\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 6.2953 - mae: 6.2953\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.2702 - mae: 6.2702\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.2448 - mae: 6.2448\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 6.2192 - mae: 6.2192\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.1935 - mae: 6.1935\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 6.1675 - mae: 6.1675\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.1413 - mae: 6.1413\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.1148 - mae: 6.1148\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.0882 - mae: 6.0882\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 6.0613 - mae: 6.0613\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.0341 - mae: 6.0341\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 6.0068 - mae: 6.0068\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.9791 - mae: 5.9791\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.9513 - mae: 5.9513\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.9231 - mae: 5.9231\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.8947 - mae: 5.8947\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.8763 - mae: 5.8763\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 5.8738 - mae: 5.8738\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.9856 - mae: 5.9856\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.8031 - mae: 5.8031\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 5.7738 - mae: 5.7738\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.7442 - mae: 5.7442\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.7144 - mae: 5.7144\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.6842 - mae: 5.6842\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.6538 - mae: 5.6538\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.6230 - mae: 5.6230\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.5919 - mae: 5.5919\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.5605 - mae: 5.5605\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.5287 - mae: 5.5287\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.5201 - mae: 5.5201\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.5384 - mae: 5.5384\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.6340 - mae: 5.6340\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.4264 - mae: 5.4264\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.3935 - mae: 5.3935\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.3602 - mae: 5.3602\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.3265 - mae: 5.3265\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.2925 - mae: 5.2925\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.2581 - mae: 5.2581\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.2233 - mae: 5.2233\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.1881 - mae: 5.1881\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.1559 - mae: 5.1559\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.2690 - mae: 5.2690\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.2731 - mae: 5.2731\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.0743 - mae: 5.0743\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.0376 - mae: 5.0376\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 5.0005 - mae: 5.0005\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 4.9629 - mae: 4.9629\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f0ec673fe10>"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X, y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8hZI_5tsiJUv",
        "outputId": "98743b76-1dae-484b-f474-dc8ec3c9b6f5"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(8,), dtype=float32, numpy=array([-7., -4., -1.,  2.,  5.,  8., 11., 14.], dtype=float32)>,\n",
              " <tf.Tensor: shape=(8,), dtype=float32, numpy=array([ 3.,  6.,  9., 12., 15., 18., 21., 24.], dtype=float32)>)"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.predict([17.0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VvxDf8qUiJ3C",
        "outputId": "1dd1e903-bc0c-4112-9f09-d37a26c5e219"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f0ecab36710> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[29.716785]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The loss is higher than the previous case, but the predicted label is closer to the actual label; overfitting doesn't occur"
      ],
      "metadata": {
        "id": "S8M8Sy1qiNkD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Changing the Optimization function"
      ],
      "metadata": {
        "id": "VDzVrJuYlEE5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# using optimizer = Adam instead of SGD\n",
        "\n",
        "model = tf.keras.Sequential([tf.keras.layers.Dense(50, activation=None),\n",
        "                             tf.keras.layers.Dense(1)])\n",
        "\n",
        "model.compile(loss='mae',\n",
        "              optimizer=tf.keras.optimizers.Adam(),\n",
        "              metrics='mae')\n",
        "\n",
        "model.fit(tf.expand_dims(X, axis=-1), y, epochs=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3_Aba7FpidAo",
        "outputId": "0ad7e6a1-69be-43a4-ef9a-f86c7a9d4c79"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1/1 [==============================] - 0s 470ms/step - loss: 12.0125 - mae: 12.0125\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 11.9367 - mae: 11.9367\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 11.8608 - mae: 11.8608\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 11.7848 - mae: 11.7848\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 11.7088 - mae: 11.7088\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 11.6327 - mae: 11.6327\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 11.5565 - mae: 11.5565\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 11.4802 - mae: 11.4802\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 11.4039 - mae: 11.4039\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 11.3274 - mae: 11.3274\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 11.2509 - mae: 11.2509\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 11.1742 - mae: 11.1742\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 11.0975 - mae: 11.0975\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 11.0207 - mae: 11.0207\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 10.9437 - mae: 10.9437\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 10.8667 - mae: 10.8667\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 10.7895 - mae: 10.7895\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 10.7123 - mae: 10.7123\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 10.6348 - mae: 10.6348\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 10.5573 - mae: 10.5573\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 10.4796 - mae: 10.4796\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 10.4018 - mae: 10.4018\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 10.3238 - mae: 10.3238\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 10.2457 - mae: 10.2457\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 10.1673 - mae: 10.1673\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 10.0889 - mae: 10.0889\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 10.0102 - mae: 10.0102\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 9.9313 - mae: 9.9313\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 9.8523 - mae: 9.8523\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 9.7730 - mae: 9.7730\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 9.6935 - mae: 9.6935\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 9.6139 - mae: 9.6139\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 9.5339 - mae: 9.5339\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 9.4538 - mae: 9.4538\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 9.3734 - mae: 9.3734\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 9.2927 - mae: 9.2927\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 9.2118 - mae: 9.2118\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 9.1306 - mae: 9.1306\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 9.0492 - mae: 9.0492\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 8.9674 - mae: 8.9674\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 8.8854 - mae: 8.8854\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 8.8031 - mae: 8.8031\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 8.7204 - mae: 8.7204\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 8.6375 - mae: 8.6375\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 8.5542 - mae: 8.5542\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.4705 - mae: 8.4705\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.3866 - mae: 8.3866\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.3022 - mae: 8.3022\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 8.2175 - mae: 8.2175\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 8.1325 - mae: 8.1325\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.0471 - mae: 8.0471\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 7.9612 - mae: 7.9612\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 7.8750 - mae: 7.8750\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 7.7884 - mae: 7.7884\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.7014 - mae: 7.7014\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 7.6140 - mae: 7.6140\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 7.5262 - mae: 7.5262\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 7.4379 - mae: 7.4379\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 7.3492 - mae: 7.3492\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 7.2601 - mae: 7.2601\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 7.1705 - mae: 7.1705\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 7.0805 - mae: 7.0805\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 6.9900 - mae: 6.9900\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 6.9561 - mae: 6.9561\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 6.9460 - mae: 6.9460\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 6.9361 - mae: 6.9361\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 6.9263 - mae: 6.9263\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 6.9168 - mae: 6.9168\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 6.9074 - mae: 6.9074\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 6.8981 - mae: 6.8981\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 6.8889 - mae: 6.8889\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.8798 - mae: 6.8798\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 6.8709 - mae: 6.8709\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 6.8620 - mae: 6.8620\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 6.8531 - mae: 6.8531\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 6.8497 - mae: 6.8497\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 6.8569 - mae: 6.8569\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 6.8576 - mae: 6.8576\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 6.8525 - mae: 6.8525\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 6.8421 - mae: 6.8421\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 6.8270 - mae: 6.8270\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 6.8077 - mae: 6.8077\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 6.7935 - mae: 6.7935\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 6.7870 - mae: 6.7870\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 6.7803 - mae: 6.7803\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 6.7734 - mae: 6.7734\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 6.7664 - mae: 6.7664\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.7593 - mae: 6.7593\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 6.7520 - mae: 6.7520\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 6.7446 - mae: 6.7446\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 6.7371 - mae: 6.7371\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 6.7295 - mae: 6.7295\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 6.7218 - mae: 6.7218\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 6.7141 - mae: 6.7141\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 6.7062 - mae: 6.7062\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 6.6983 - mae: 6.6983\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 6.6903 - mae: 6.6903\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 6.6822 - mae: 6.6822\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 6.6741 - mae: 6.6741\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 6.6658 - mae: 6.6658\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f0ecaba58d0>"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X, y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9cN2xyQciq_3",
        "outputId": "484295ff-688e-4ba8-9a88-9a60a1ba1a76"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(8,), dtype=float32, numpy=array([-7., -4., -1.,  2.,  5.,  8., 11., 14.], dtype=float32)>,\n",
              " <tf.Tensor: shape=(8,), dtype=float32, numpy=array([ 3.,  6.,  9., 12., 15., 18., 21., 24.], dtype=float32)>)"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.predict([17.])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "or3tXe3wisO2",
        "outputId": "c490e647-9ffb-4b85-9afa-90c700071bce"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[31.25573]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Change the learning rate in Optimization function"
      ],
      "metadata": {
        "id": "PamXvUFOlJ6Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Changing learning rate in adam optimizer (here lr = 0.01 instead of the default lr = 0.001)\n",
        "\n",
        "model = tf.keras.Sequential([tf.keras.layers.Dense(100, activation=None),\n",
        "                             tf.keras.layers.Dense(1)])\n",
        "\n",
        "model.compile(loss='mae',\n",
        "              optimizer=tf.keras.optimizers.Adam(lr=0.01),\n",
        "              metrics='mae')\n",
        "\n",
        "model.fit(tf.expand_dims(X, axis=-1), y, epochs=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UBKiZj3SiuAN",
        "outputId": "47fa5cd3-4568-4ae9-d64c-2fbbfa30fbd7"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 464ms/step - loss: 12.8763 - mae: 12.8763\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 11.8505 - mae: 11.8505\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 10.8183 - mae: 10.8183\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 9.7764 - mae: 9.7764\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 8.7186 - mae: 8.7186\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 7.6372 - mae: 7.6372\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 6.8147 - mae: 6.8147\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 7.1374 - mae: 7.1374\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 7.5567 - mae: 7.5567\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 7.7356 - mae: 7.7356\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 7.5726 - mae: 7.5726\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 7.1766 - mae: 7.1766\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 6.7813 - mae: 6.7813\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 6.4021 - mae: 6.4021\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 6.1025 - mae: 6.1025\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 6.0363 - mae: 6.0363\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.2205 - mae: 6.2205\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 6.2891 - mae: 6.2891\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.2107 - mae: 6.2107\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 6.0047 - mae: 6.0047\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.6844 - mae: 5.6844\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 5.3657 - mae: 5.3657\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.2102 - mae: 5.2102\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.1886 - mae: 5.1886\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.1747 - mae: 5.1747\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.0960 - mae: 5.0960\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 4.9569 - mae: 4.9569\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 4.7622 - mae: 4.7622\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 4.5160 - mae: 4.5160\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 4.2222 - mae: 4.2222\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 4.0313 - mae: 4.0313\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.9312 - mae: 3.9312\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.8237 - mae: 3.8237\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.5460 - mae: 3.5460\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 3.2492 - mae: 3.2492\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 3.0541 - mae: 3.0541\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.9018 - mae: 2.9018\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.6729 - mae: 2.6729\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.3696 - mae: 2.3696\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.9999 - mae: 1.9999\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.7291 - mae: 1.7291\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.5459 - mae: 1.5459\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.1531 - mae: 1.1531\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.8519 - mae: 0.8519\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5959 - mae: 0.5959\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0727 - mae: 0.0727\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.7652 - mae: 0.7652\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.0392 - mae: 1.0392\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.9412 - mae: 0.9412\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.2391 - mae: 1.2391\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.5206 - mae: 1.5206\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.5010 - mae: 1.5010\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.2212 - mae: 1.2212\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.1649 - mae: 1.1649\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.2379 - mae: 1.2379\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.0535 - mae: 1.0535\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6556 - mae: 0.6556\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5584 - mae: 0.5584\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4363 - mae: 0.4363\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2694 - mae: 0.2694\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4216 - mae: 0.4216\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6867 - mae: 0.6867\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.7250 - mae: 0.7250\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5651 - mae: 0.5651\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6443 - mae: 0.6443\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.7830 - mae: 0.7830\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6160 - mae: 0.6160\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.3155 - mae: 0.3155\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.3229 - mae: 0.3229\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1366 - mae: 0.1366\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2279 - mae: 0.2279\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.3568 - mae: 0.3568\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.2709 - mae: 0.2709\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5375 - mae: 0.5375\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5759 - mae: 0.5759\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.3033 - mae: 0.3033\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.3255 - mae: 0.3255\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.4930 - mae: 0.4930\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.3380 - mae: 0.3380\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.2567 - mae: 0.2567\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.4359 - mae: 0.4359\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.3759 - mae: 0.3759\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1472 - mae: 0.1472\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5166 - mae: 0.5166\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6017 - mae: 0.6017\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.3588 - mae: 0.3588\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2475 - mae: 0.2475\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4421 - mae: 0.4421\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.3415 - mae: 0.3415\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2315 - mae: 0.2315\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2790 - mae: 0.2790\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1036 - mae: 0.1036\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.3564 - mae: 0.3564\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4566 - mae: 0.4566\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.3030 - mae: 0.3030\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2335 - mae: 0.2335\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2989 - mae: 0.2989\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1154 - mae: 0.1154\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.3313 - mae: 0.3313\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.3732 - mae: 0.3732\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f0ecc303710>"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X, y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jR6FsLpWjD0k",
        "outputId": "c22f7057-7709-4c4b-b1b9-012cb1d67925"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(8,), dtype=float32, numpy=array([-7., -4., -1.,  2.,  5.,  8., 11., 14.], dtype=float32)>,\n",
              " <tf.Tensor: shape=(8,), dtype=float32, numpy=array([ 3.,  6.,  9., 12., 15., 18., 21., 24.], dtype=float32)>)"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.predict([17.0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tz6gEK1mjEVn",
        "outputId": "4326ebc9-44c4-40a5-b602-c1b827309710"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[26.71068]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This model has a very low loss of 0.3732 and a predicted label of 26.71 which is very close to the actual label of 26.0; our best model as of yet.\n",
        "\n",
        "The **Learning Rate** is **potentially the most important HPT we can change in the neural network**."
      ],
      "metadata": {
        "id": "LfMgE0EGjHPX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluating a Model"
      ],
      "metadata": {
        "id": "Yeh1ZjnXlXbT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " "
      ],
      "metadata": {
        "id": "ix-CeQ7EjW1a"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}